version: "3"
services:
  #------------------------------------------------------------------------------------------------
  # hadoop cluster
  #------------------------------------------------------------------------------------------------
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    networks:
      - backend
    restart: on-failure
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9861 datanode2:9862 datanode3:9863 "
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - datanode3
    env_file:
      - ./hadoop.env
    ports: 
     - "8089:8088"

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    networks:
      - backend
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9861 datanode2:9862 datanode3:9863 resourcemanager:8088"
    depends_on: 
      - namenode
      - datanode1
      - datanode2
    volumes:
      - ./data/historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    ports: 
      - "8188:8188"

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager1
    networks:
      - backend
    environment:
     SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9861 datanode2:9862 datanode3:9863 resourcemanager:8088"
    depends_on: 
      - namenode
      - datanode1
      - datanode2
    env_file:
      - ./hadoop.env
    ports: 
      - "8042:8042"

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    hostname: datanode1
    networks:
      - backend
    volumes:
      - ./data/datanode1:/hadoop/dfs/data
    environment:
     SERVICE_PRECONDITION: "namenode:9870"
    depends_on:
      - namenode
    env_file:
      - ./hadoop.env
    environment: 
      HDFS_CONF_dfs_datanode_http_address: "0.0.0.0:9861"
    ports:
      - 9861:9861

  datanode2:
    # build: ./datanode
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    hostname: datanode2
    networks:
      - backend
    volumes:
      - ./data/datanode2:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    depends_on:
      - namenode
    env_file:
      - ./hadoop.env
    environment: 
      HDFS_CONF_dfs_datanode_http_address: "0.0.0.0:9862"
    ports:
      - 9862:9862

  datanode3:
    # build: ./datanode
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode3
    hostname: datanode3
    networks:
      - backend
    volumes:
      - ./data/datanode3:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    depends_on:
      - namenode
    env_file:
      - ./hadoop.env
    environment: 
      HDFS_CONF_dfs_datanode_http_address: "0.0.0.0:9863"
    ports:
      - 9863:9863

  namenode:
    # build: ./namenode
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    hostname: namenode
    networks:
      - backend
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - ./data/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=rudi_das_ruesselcluster
    env_file:
      - ./hadoop.env

  #------------------------------------------------------------------------------------------------
  # databases
  #------------------------------------------------------------------------------------------------
  mongodb:
    image: mongo:4.2-bionic
    container_name: mongodb
    command: mongod
    networks:
      - backend
    ports:
      - 27017:27017
    env_file: ../variables.env
    volumes:
      - ./data/mongodb:/data/db

  postgres:
    image: postgres
    container_name: postgres
    networks:
      - backend
    ports:
      - 5432:5432
    env_file: ../variables.env
    volumes: 
      - ./data/postgres:/var/lib/postgresql/data

  #------------------------------------------------------------------------------------------------
  # spark cluster
  #------------------------------------------------------------------------------------------------
  master:
    image: semanticdatalake21/spark-master:latest
    container_name: master
    ports:
      - 8088:8080
      - 7077:7077
      - 4040:4040
    networks:
      - backend

  worker-1:
    image: semanticdatalake21/spark-worker:latest
    container_name: worker-1
    depends_on:
      - master
    env_file: ../variables.env
    ports:
      - 8081:8081
    networks:
      - backend

  worker-2:
    image: semanticdatalake21/spark-worker:latest
    container_name: worker-2
    depends_on:
      - master
    env_file: ../variables.env
    ports:
      - 8082:8081
    networks:
      - backend

  fuseki:
    image: stain/jena-fuseki
    container_name: fuseki
    ports:
      - 3030:3030
    networks:
      - backend
    environment:
      - ADMIN_PASSWORD=pw123
  #------------------------------------------------------------------------------------------------
  # application
  #------------------------------------------------------------------------------------------------
  backend:
    image: semanticdatalake21/backend:refactor
    container_name: backend
    depends_on:
      - mongodb
      - postgres
    env_file: ../variables.env
    ports:
      - 5000:5000
    networks:
      - backend
    volumes:
      - /home/mapro2020/refactor/team-2-data-lake/datalake_config.yml:/datalake_config.yml # change your relative path

  pier:
    image: semanticdatalake21/pier:refactor
    container_name: pier
    depends_on:
      - backend
    ports:
      - 80:80

  #------------------------------------------------------------------------------------------------
  # misc
  #------------------------------------------------------------------------------------------------
  zeppelin:
    image: apache/zeppelin:0.9.0
    container_name: zeppelin
    networks:
      - backend
    ports:
      - 8070:8080

networks:
  backend:
    external: false
