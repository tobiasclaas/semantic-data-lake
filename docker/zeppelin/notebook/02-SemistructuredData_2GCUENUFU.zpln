{
  "paragraphs": [
    {
      "text": "%md\n\n### Requirements for this Notebook\n\nIf you want to run this notebook in your local Zeppelin installation, you need to add the following dependencies to the spark interpreter:\n\n* org.mongodb.spark:mongo-spark-connector_2.11:jar:2.4.3 \t\n* com.databricks:spark-xml_2.11:jar:0.5.0 \t\n\nFurthermore, you might have to adapt the paths to the files, in case they are not located in the subdirectory `data`.\n\nFinally, Java should be in version 1.8.x and Scala should be in version 2.11.x. A newer Java version breaks the join operation below. Another Scala version requires at least a change of the dependencies, e.g., `org.mongodb.spark:mongo-spark-connector_2.12:jar:x.y.z` instead of `org.mongodb.spark:mongo-spark-connector_2.11:jar:2.4.3`.\n",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:18.999",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eRequirements for this Notebook\u003c/h3\u003e\n\u003cp\u003eIf you want to run this notebook in your local Zeppelin installation, you need to add the following dependencies to the spark interpreter:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eorg.mongodb.spark:mongo-spark-connector_2.11:jar:2.4.3\u003c/li\u003e\n\u003cli\u003ecom.databricks:spark-xml_2.11:jar:0.5.0\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFurthermore, you might have to adapt the paths to the files, in case they are not located in the subdirectory \u003ccode\u003edata\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFinally, Java should be in version 1.8.x and Scala should be in version 2.11.x. A newer Java version breaks the join operation below. Another Scala version requires at least a change of the dependencies, e.g., \u003ccode\u003eorg.mongodb.spark:mongo-spark-connector_2.12:jar:x.y.z\u003c/code\u003e instead of \u003ccode\u003eorg.mongodb.spark:mongo-spark-connector_2.11:jar:2.4.3\u003c/code\u003e.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082091_1656954369",
      "id": "paragraph_1621605922896_1481741954",
      "dateCreated": "2021-07-08 15:28:02.091",
      "dateStarted": "2021-07-08 15:28:18.999",
      "dateFinished": "2021-07-08 15:28:20.787",
      "status": "FINISHED"
    },
    {
      "text": "%md\n\n## Reading JSON data in Spark\n\nReading JSON files is as simple as reading CSV files. A schema is also inferred automatically.",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.092",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eReading JSON data in Spark\u003c/h2\u003e\n\u003cp\u003eReading JSON files is as simple as reading CSV files. A schema is also inferred automatically.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082092_1331508764",
      "id": "20180701-070656_502745265",
      "dateCreated": "2021-07-08 15:28:02.092",
      "status": "READY"
    },
    {
      "text": "%md\n\n## Data Ingestion of Raw Data\n\nWe can write the data directly to MongoDB. Update the `db` variable before executing the next cell.\n\n### Question?\nWhy is it not possible to write it to PostgreSQL? Try it by adapting the code from the previous notebook.",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.093",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eData Ingestion of Raw Data\u003c/h2\u003e\n\u003cp\u003eWe can write the data directly to MongoDB. Update the \u003ccode\u003edb\u003c/code\u003e variable before executing the next cell.\u003c/p\u003e\n\u003ch3\u003eQuestion?\u003c/h3\u003e\n\u003cp\u003eWhy is it not possible to write it to PostgreSQL? Try it by adapting the code from the previous notebook.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082093_1479956793",
      "id": "20180701-180012_1979196646",
      "dateCreated": "2021-07-08 15:28:02.093",
      "status": "READY"
    },
    {
      "text": "import com.mongodb.spark.MongoSpark\nimport com.mongodb.spark.config.{ReadConfig, WriteConfig}\nimport com.mongodb.{ConnectionString, WriteConcern}\n\n\nval db \u003d \"bdtXXX\"\n\nval writeConfig \u003d WriteConfig(db,\"teamdata\",\"mongodb://localhost/\",1000,WriteConcern.MAJORITY)\nMongoSpark.save(teamData,writeConfig)\n",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:31:13.690",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.zeppelin.interpreter.InterpreterException: java.io.IOException: Interpreter process is not running\n/opt/zeppelin/bin/interpreter.sh: line 294: /usr/local/spark//bin/spark-submit: No such file or directory\n\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:129)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getFormType(RemoteInterpreter.java:271)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:444)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:72)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:182)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: Interpreter process is not running\n/opt/zeppelin/bin/interpreter.sh: line 294: /usr/local/spark//bin/spark-submit: No such file or directory\n\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.internal_create(RemoteInterpreter.java:157)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:126)\n\t... 13 more\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082093_1202074034",
      "id": "20180701-180101_1561223770",
      "dateCreated": "2021-07-08 15:28:02.093",
      "dateStarted": "2021-07-08 15:31:13.694",
      "dateFinished": "2021-07-08 15:31:13.698",
      "status": "ERROR"
    },
    {
      "text": "%md\n\nCheck whether the data has been inserted successfully by connecting to MongoDB directly, using the interpreter `%mongodb_bdtX` as in chapter 2.\n",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.093",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCheck whether the data has been inserted successfully by connecting to MongoDB directly, using the interpreter \u003ccode\u003e%mongodb_bdtX\u003c/code\u003e as in chapter 2.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082093_1256860403",
      "id": "paragraph_1621605298673_326648981",
      "dateCreated": "2021-07-08 15:28:02.093",
      "status": "READY"
    },
    {
      "text": "%mongodb_bdtXX\n\ndb.teamdata.find().forEach(printjson)",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.093",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/text",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082093_541142440",
      "id": "paragraph_1621605251760_1849145363",
      "dateCreated": "2021-07-08 15:28:02.093",
      "status": "READY"
    },
    {
      "text": "%md\n\n## Extracting Metadata\n\nMetadata is automatically extracted (or generated) from the JSON file while reading it into a DataFrame. Each DataFrame is associated with metadata which can be shown with `printSchema`.",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.093",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eExtracting Metadata\u003c/h2\u003e\n\u003cp\u003eMetadata is automatically extracted (or generated) from the JSON file while reading it into a DataFrame. Each DataFrame is associated with metadata which can be shown with \u003ccode\u003eprintSchema\u003c/code\u003e.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082093_53153077",
      "id": "20180701-172351_387289613",
      "dateCreated": "2021-07-08 15:28:02.093",
      "status": "READY"
    },
    {
      "text": "teamData.printSchema()",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.093",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082093_2063452355",
      "id": "20180701-071005_1024841444",
      "dateCreated": "2021-07-08 15:28:02.093",
      "status": "READY"
    },
    {
      "text": "%md\n\n## Data Transformation for JSON Data\n\nThe TeamData JSON file is a deeply nested structure which is not easily usable directly in Spark. We have to \"flatten\" it with a sequence of `select` and `explode` functions.\n\n* `df.select(c1,c2,...,cn)`: Creates a new DataFrame from `df` by applying the expressions c1, c2, ..., cn to the columns of the input DataFrame.\n* `df.explode($\"ArrayCol\").as(\"N\")`: Unrolls the array in the column `ArrayCol` and makes the individual values available in the column `N`.\n* `$\"NAME\" or col(NAME)`: Refers to the column `NAME` from the current DataFrame.\n\nThere are many other functions that can be applied to columns of a DataFrame. A full list is available [here](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$).\n \nThe following example transforms the input table with the nested JSON document into a flat table with player name and team name.\n\n",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.093",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eData Transformation for JSON Data\u003c/h2\u003e\n\u003cp\u003eThe TeamData JSON file is a deeply nested structure which is not easily usable directly in Spark. We have to \u0026ldquo;flatten\u0026rdquo; it with a sequence of \u003ccode\u003eselect\u003c/code\u003e and \u003ccode\u003eexplode\u003c/code\u003e functions.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edf.select(c1,c2,...,cn)\u003c/code\u003e: Creates a new DataFrame from \u003ccode\u003edf\u003c/code\u003e by applying the expressions c1, c2, \u0026hellip;, cn to the columns of the input DataFrame.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edf.explode($\u0026quot;ArrayCol\u0026quot;).as(\u0026quot;N\u0026quot;)\u003c/code\u003e: Unrolls the array in the column \u003ccode\u003eArrayCol\u003c/code\u003e and makes the individual values available in the column \u003ccode\u003eN\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e$\u0026quot;NAME\u0026quot; or col(NAME)\u003c/code\u003e: Refers to the column \u003ccode\u003eNAME\u003c/code\u003e from the current DataFrame.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere are many other functions that can be applied to columns of a DataFrame. A full list is available \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe following example transforms the input table with the nested JSON document into a flat table with player name and team name.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082093_225482605",
      "id": "20180701-172959_2080017057",
      "dateCreated": "2021-07-08 15:28:02.093",
      "status": "READY"
    },
    {
      "text": "val teamDataExploded\u003dteamData.select(explode($\"season.TeamData\").as(\"seasonX\"))\n    .select(explode($\"seasonX.PlayerData\").as(\"player\"),$\"seasonX.TeamName\".as(\"TeamName\"))\n    .select($\"player.Player_Name\".as(\"PlayerName\"),$\"TeamName\")\n    .withColumn(\"PlayerID\",monotonically_increasing_id())\n\nteamDataExploded.show()\n",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.093",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {
          "1": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------------------+-------------+--------+\n|         PlayerName|     TeamName|PlayerID|\n+-------------------+-------------+--------+\n|    Benaglio, Diego|vfl-wolfsburg|       0|\n|          Grün, Max|vfl-wolfsburg|       1|\n|     Hasebe, Makoto|vfl-wolfsburg|       2|\n|        Klose, Timm|vfl-wolfsburg|       3|\n|      Knoche, Robin|vfl-wolfsburg|       4|\n|              Naldo|vfl-wolfsburg|       5|\n|      Ochs, Patrick|vfl-wolfsburg|       6|\n| Rodriguez, Ricardo|vfl-wolfsburg|       7|\n|    Schäfer, Marcel|vfl-wolfsburg|       8|\n|  Träsch, Christian|vfl-wolfsburg|       9|\n| Arnold, Maximilian|vfl-wolfsburg|      10|\n|  Caligiuri, Daniel|vfl-wolfsburg|      11|\n|   De Bruyne, Kevin|vfl-wolfsburg|      12|\n|              Diego|vfl-wolfsburg|      13|\n|      Evseev, Willi|vfl-wolfsburg|      14|\n|     Junior Malanda|vfl-wolfsburg|      15|\n|      Koo, Ja-Cheol|vfl-wolfsburg|      16|\n|       Luiz Gustavo|vfl-wolfsburg|      17|\n|Medojevic, Slobodan|vfl-wolfsburg|      18|\n|         Polak, Jan|vfl-wolfsburg|      19|\n+-------------------+-------------+--------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mteamDataExploded\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [PlayerName: string, TeamName: string ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082093_80703918",
      "id": "20180701-071023_1559379745",
      "dateCreated": "2021-07-08 15:28:02.093",
      "status": "READY"
    },
    {
      "text": "%md\n\n## Reading XML Data in Spark\n\nReading XML data is very similar to reading CSV or JSON data. The extracted data is also stored in a DataFrame with nesting, the extracted schema is also very similar to that one extracted from the JSON file.\n\nWe have to specify the XML element (`rowTag`) for which a row will be created in the DataFrame. Here, we will use `Match`. In case we would like to have a row for each goal, we need to explode the `Goals` element.",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.093",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eReading XML Data in Spark\u003c/h2\u003e\n\u003cp\u003eReading XML data is very similar to reading CSV or JSON data. The extracted data is also stored in a DataFrame with nesting, the extracted schema is also very similar to that one extracted from the JSON file.\u003c/p\u003e\n\u003cp\u003eWe have to specify the XML element (\u003ccode\u003erowTag\u003c/code\u003e) for which a row will be created in the DataFrame. Here, we will use \u003ccode\u003eMatch\u003c/code\u003e. In case we would like to have a row for each goal, we need to explode the \u003ccode\u003eGoals\u003c/code\u003e element.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082093_1762798421",
      "id": "20180701-174059_933747689",
      "dateCreated": "2021-07-08 15:28:02.093",
      "status": "READY"
    },
    {
      "text": "val matchxml \u003d spark.read\n  .format(\"com.databricks.spark.xml\")\n  .option(\"rowTag\", \"Match\")\n  .load(\"data/buli/MatchData_13.xml\")\n  \nmatchxml.printSchema()\n",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.094",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- Goals: struct (nullable \u003d true)\n |    |-- Goal: array (nullable \u003d true)\n |    |    |-- element: struct (containsNull \u003d true)\n |    |    |    |-- Comment: struct (nullable \u003d true)\n |    |    |    |    |-- _VALUE: string (nullable \u003d true)\n |    |    |    |    |-- _nil: boolean (nullable \u003d true)\n |    |    |    |-- GoalGetterID: long (nullable \u003d true)\n |    |    |    |-- GoalGetterName: string (nullable \u003d true)\n |    |    |    |-- GoalID: long (nullable \u003d true)\n |    |    |    |-- IsOvertime: boolean (nullable \u003d true)\n |    |    |    |-- IsOwnGoal: boolean (nullable \u003d true)\n |    |    |    |-- IsPenalty: boolean (nullable \u003d true)\n |    |    |    |-- MatchMinute: struct (nullable \u003d true)\n |    |    |    |    |-- _VALUE: long (nullable \u003d true)\n |    |    |    |    |-- _nil: boolean (nullable \u003d true)\n |    |    |    |-- ScoreTeam1: long (nullable \u003d true)\n |    |    |    |-- ScoreTeam2: long (nullable \u003d true)\n |-- Group: struct (nullable \u003d true)\n |    |-- GroupID: long (nullable \u003d true)\n |    |-- GroupName: string (nullable \u003d true)\n |    |-- GroupOrderID: long (nullable \u003d true)\n |-- LastUpdateDateTime: string (nullable \u003d true)\n |-- LeagueId: long (nullable \u003d true)\n |-- LeagueName: string (nullable \u003d true)\n |-- Location: struct (nullable \u003d true)\n |    |-- LocationCity: string (nullable \u003d true)\n |    |-- LocationID: long (nullable \u003d true)\n |    |-- LocationStadium: string (nullable \u003d true)\n |-- MatchDateTime: string (nullable \u003d true)\n |-- MatchDateTimeUTC: string (nullable \u003d true)\n |-- MatchID: long (nullable \u003d true)\n |-- MatchIsFinished: boolean (nullable \u003d true)\n |-- MatchResults: struct (nullable \u003d true)\n |    |-- MatchResult: array (nullable \u003d true)\n |    |    |-- element: struct (containsNull \u003d true)\n |    |    |    |-- PointsTeam1: long (nullable \u003d true)\n |    |    |    |-- PointsTeam2: long (nullable \u003d true)\n |    |    |    |-- ResultDescription: string (nullable \u003d true)\n |    |    |    |-- ResultID: long (nullable \u003d true)\n |    |    |    |-- ResultName: string (nullable \u003d true)\n |    |    |    |-- ResultOrderID: long (nullable \u003d true)\n |    |    |    |-- ResultTypeID: long (nullable \u003d true)\n |-- NumberOfViewers: struct (nullable \u003d true)\n |    |-- _VALUE: long (nullable \u003d true)\n |    |-- _nil: boolean (nullable \u003d true)\n |-- Team1: struct (nullable \u003d true)\n |    |-- ShortName: string (nullable \u003d true)\n |    |-- TeamIconUrl: string (nullable \u003d true)\n |    |-- TeamId: long (nullable \u003d true)\n |    |-- TeamName: string (nullable \u003d true)\n |-- Team2: struct (nullable \u003d true)\n |    |-- ShortName: string (nullable \u003d true)\n |    |-- TeamIconUrl: string (nullable \u003d true)\n |    |-- TeamId: long (nullable \u003d true)\n |    |-- TeamName: string (nullable \u003d true)\n |-- TimeZoneID: string (nullable \u003d true)\n\n\u001b[1m\u001b[34mmatchxml\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [Goals: struct\u003cGoal: array\u003cstruct\u003cComment:struct\u003c_VALUE:string,_nil:boolean\u003e,GoalGetterID:bigint,GoalGetterName:string,GoalID:bigint,IsOvertime:boolean,IsOwnGoal:boolean,IsPenalty:boolean,MatchMinute:struct\u003c_VALUE:bigint,_nil:boolean\u003e,ScoreTeam1:bigint,ScoreTeam2:bigint\u003e\u003e\u003e, Group: struct\u003cGroupID: bigint, GroupName: string ... 1 more field\u003e ... 13 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082094_1704719197",
      "id": "20180701-071900_695177398",
      "dateCreated": "2021-07-08 15:28:02.094",
      "status": "READY"
    },
    {
      "text": "%md\n\n## Data Ingestion of XML Data\n\nXML data can also be written directly to MongoDB without any data transformation. The following code is identical to the code above for writing JSON data.",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.094",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eData Ingestion of XML Data\u003c/h2\u003e\n\u003cp\u003eXML data can also be written directly to MongoDB without any data transformation. The following code is identical to the code above for writing JSON data.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082094_697045639",
      "id": "20180701-201226_1922215550",
      "dateCreated": "2021-07-08 15:28:02.094",
      "status": "READY"
    },
    {
      "text": "val writeConfig \u003d WriteConfig(db,\"matchdata\",\"mongodb://localhost/\",1000,WriteConcern.MAJORITY)\nMongoSpark.save(matchxml,writeConfig)\n",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.094",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u003cconsole\u003e:25: \u001b[31merror: \u001b[0mnot found: value WriteConfig\n       val writeConfig \u003d WriteConfig(db,\"matchdata\",\"mongodb://localhost/\",1000,WriteConcern.MAJORITY)\n                         ^\n\u003cconsole\u003e:25: \u001b[31merror: \u001b[0mnot found: value db\n       val writeConfig \u003d WriteConfig(db,\"matchdata\",\"mongodb://localhost/\",1000,WriteConcern.MAJORITY)\n                                     ^\n\u003cconsole\u003e:25: \u001b[31merror: \u001b[0mnot found: value WriteConcern\n       val writeConfig \u003d WriteConfig(db,\"matchdata\",\"mongodb://localhost/\",1000,WriteConcern.MAJORITY)\n                                                                                ^\n\u003cconsole\u003e:28: \u001b[31merror: \u001b[0mnot found: value MongoSpark\n       MongoSpark.save(matchxml,writeConfig)\n       ^\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082094_1777610132",
      "id": "20180701-074524_1982471567",
      "dateCreated": "2021-07-08 15:28:02.094",
      "status": "READY"
    },
    {
      "text": "%md\n\n## Data Transformation for XML Data\n\nData transformation for XML data is done in the same way as for JSON data, i.e., by applying a sequence of functions to a DataFrame. \nWe want to create a table according to the following mapping.\n\n|XML field | Mapped Attribute |\n|----|----|\n|MatchDateTime | MatchDateTime |\n|Goals.Goal.GoalGetterName | PlayerName|\n|Goals.Goal.IsOwnGoal|IsOwnGoal|\n|Goals.Goal.IsPenalty| IsPenalty|\n|Goals.Goal.GoalID|GoalID|\n|Team1.TeamName|TeamName1|\n|Team2.TeamName|TeamName2|\n\nThe first issue is unrolling the goal data such data we have a row for each goal in our DataFrame.\n",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.094",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eData Transformation for XML Data\u003c/h2\u003e\n\u003cp\u003eData transformation for XML data is done in the same way as for JSON data, i.e., by applying a sequence of functions to a DataFrame.\u003cbr /\u003e\nWe want to create a table according to the following mapping.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\u003cth\u003eXML field\u003c/th\u003e\u003cth\u003eMapped Attribute\u003c/th\u003e\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\u003ctd\u003eMatchDateTime\u003c/td\u003e\u003ctd\u003eMatchDateTime\u003c/td\u003e\u003c/tr\u003e\n\u003ctr\u003e\u003ctd\u003eGoals.Goal.GoalGetterName\u003c/td\u003e\u003ctd\u003ePlayerName\u003c/td\u003e\u003c/tr\u003e\n\u003ctr\u003e\u003ctd\u003eGoals.Goal.IsOwnGoal\u003c/td\u003e\u003ctd\u003eIsOwnGoal\u003c/td\u003e\u003c/tr\u003e\n\u003ctr\u003e\u003ctd\u003eGoals.Goal.IsPenalty\u003c/td\u003e\u003ctd\u003eIsPenalty\u003c/td\u003e\u003c/tr\u003e\n\u003ctr\u003e\u003ctd\u003eGoals.Goal.GoalID\u003c/td\u003e\u003ctd\u003eGoalID\u003c/td\u003e\u003c/tr\u003e\n\u003ctr\u003e\u003ctd\u003eTeam1.TeamName\u003c/td\u003e\u003ctd\u003eTeamName1\u003c/td\u003e\u003c/tr\u003e\n\u003ctr\u003e\u003ctd\u003eTeam2.TeamName\u003c/td\u003e\u003ctd\u003eTeamName2\u003c/td\u003e\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThe first issue is unrolling the goal data such data we have a row for each goal in our DataFrame.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082094_645820209",
      "id": "20180701-210548_965922610",
      "dateCreated": "2021-07-08 15:28:02.094",
      "status": "READY"
    },
    {
      "text": "// Now, unroll the Goals element to get a row for each goal\n\nval goaldf\u003dmatchxml.select(explode($\"Goals.Goal\").as(\"Goal\"),\n        $\"MatchDateTime\",\n        $\"Team1.TeamName\".as(\"TeamName1\"),\n        $\"Team2.TeamName\".as(\"TeamName2\"))\n    .select($\"Goal.GoalGetterName\".as(\"PlayerName\"),\n        $\"MatchDateTime\",\n        $\"Goal.IsOwnGoal\".as(\"IsOwnGoal\"),\n        $\"Goal.IsPenalty\".as(\"IsPenalty\"),\n        $\"Goal.GoalID\".as(\"GoalID\"),\n        $\"TeamName1\",\n        $\"TeamName2\")\n\ngoaldf.show()",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.094",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------+-------------------+---------+---------+------+-------------------+--------------------+\n|      PlayerName|      MatchDateTime|IsOwnGoal|IsPenalty|GoalID|          TeamName1|           TeamName2|\n+----------------+-------------------+---------+---------+------+-------------------+--------------------+\n|Mandzukic, Mario|2013-08-09T20:30:00|    false|    false| 21118|     Bayern München|Borussia Möncheng...|\n|   Robben, Arjen|2013-08-09T20:30:00|    false|    false| 21119|     Bayern München|Borussia Möncheng...|\n|           Dante|2013-08-09T20:30:00|     true|    false| 21132|     Bayern München|Borussia Möncheng...|\n|    Alaba, David|2013-08-09T20:30:00|    false|     true| 21133|     Bayern München|Borussia Möncheng...|\n|        Kießling|2013-08-10T15:30:00|    false|    false| 21136|Bayer 04 Leverkusen|         SC Freiburg|\n|           Hanke|2013-08-10T15:30:00|    false|    false| 21144|Bayer 04 Leverkusen|         SC Freiburg|\n|             Son|2013-08-10T15:30:00|    false|    false| 21145|Bayer 04 Leverkusen|         SC Freiburg|\n|             Sam|2013-08-10T15:30:00|    false|    false| 21146|Bayer 04 Leverkusen|         SC Freiburg|\n|       Andreasen|2013-08-10T15:30:00|    false|    false| 21134|        Hannover 96|       VfL Wolfsburg|\n|          Huszti|2013-08-10T15:30:00|    false|    false| 21155|        Hannover 96|       VfL Wolfsburg|\n|         Abraham|2013-08-10T15:30:00|    false|    false| 21142|TSG 1899 Hoffenheim|      1. FC Nürnberg|\n|         Modeste|2013-08-10T15:30:00|    false|    false| 21147|TSG 1899 Hoffenheim|      1. FC Nürnberg|\n|          Frantz|2013-08-10T15:30:00|    false|    false| 21148|TSG 1899 Hoffenheim|      1. FC Nürnberg|\n|         Ginczek|2013-08-10T15:30:00|    false|    false| 21149|TSG 1899 Hoffenheim|      1. FC Nürnberg|\n|      Aubameyang|2013-08-10T15:30:00|    false|    false| 21137|        FC Augsburg|   Borussia Dortmund|\n|      Aubameyang|2013-08-10T15:30:00|    false|    false| 21152|        FC Augsburg|   Borussia Dortmund|\n|      Aubameyang|2013-08-10T15:30:00|    false|    false| 21154|        FC Augsburg|   Borussia Dortmund|\n|     Lewandowski|2013-08-10T15:30:00|    false|     true| 21156|        FC Augsburg|   Borussia Dortmund|\n|           Ramos|2013-08-10T15:30:00|    false|    false| 21135|         Hertha BSC| Eintracht Frankfurt|\n|          Brooks|2013-08-10T15:30:00|    false|    false| 21141|         Hertha BSC| Eintracht Frankfurt|\n+----------------+-------------------+---------+---------+------+-------------------+--------------------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mgoaldf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [PlayerName: string, MatchDateTime: string ... 5 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082094_1183759039",
      "id": "20180701-195737_1890503832",
      "dateCreated": "2021-07-08 15:28:02.094",
      "status": "READY"
    },
    {
      "text": "%md \n\n## Joining DataFrames\n\nNow, as we have two DataFrames with player names (`goaldf` and `teamDataExploded`), we could join them. Let\u0027s try and see the result.\n",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.094",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eJoining DataFrames\u003c/h2\u003e\n\u003cp\u003eNow, as we have two DataFrames with player names (\u003ccode\u003egoaldf\u003c/code\u003e and \u003ccode\u003eteamDataExploded\u003c/code\u003e), we could join them. Let\u0026rsquo;s try and see the result.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082094_1676559327",
      "id": "20180702-132457_290661178",
      "dateCreated": "2021-07-08 15:28:02.094",
      "status": "READY"
    },
    {
      "text": "\nval joindf\u003dgoaldf.join(teamDataExploded,goaldf.col(\"PlayerName\")\u003d\u003d\u003dteamDataExploded.col(\"PlayerName\"))\n\njoindf.createOrReplaceTempView(\"result\")\ngoaldf.createOrReplaceTempView(\"goals\")\nteamDataExploded.createOrReplaceTempView(\"teamdata\")\n\njoindf.show()",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.094",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------+-------------------+---------+---------+------+--------------------+--------------------+----------------+--------------------+--------+\n|      PlayerName|      MatchDateTime|IsOwnGoal|IsPenalty|GoalID|           TeamName1|           TeamName2|      PlayerName|            TeamName|PlayerID|\n+----------------+-------------------+---------+---------+------+--------------------+--------------------+----------------+--------------------+--------+\n|Mandzukic, Mario|2013-08-09T20:30:00|    false|    false| 21118|      Bayern München|Borussia Möncheng...|Mandzukic, Mario|     bayern-muenchen|     133|\n|   Robben, Arjen|2013-08-09T20:30:00|    false|    false| 21119|      Bayern München|Borussia Möncheng...|   Robben, Arjen|     bayern-muenchen|     127|\n|           Dante|2013-08-09T20:30:00|     true|    false| 21132|      Bayern München|Borussia Möncheng...|           Dante|     bayern-muenchen|     116|\n|    Alaba, David|2013-08-09T20:30:00|    false|     true| 21133|      Bayern München|Borussia Möncheng...|    Alaba, David|     bayern-muenchen|     113|\n|           Ronny|2013-08-10T15:30:00|    false|    false| 21157|          Hertha BSC| Eintracht Frankfurt|           Ronny|          hertha-bsc|     253|\n|       Vieirinha|2013-08-17T15:30:00|    false|    false| 21273|       VfL Wolfsburg|       FC Schalke 04|       Vieirinha|       vfl-wolfsburg|      20|\n|           Naldo|2013-08-17T15:30:00|    false|    false| 21277|       VfL Wolfsburg|       FC Schalke 04|           Naldo|       vfl-wolfsburg|       5|\n|Kutschke, Stefan|2013-08-17T15:30:00|    false|    false| 21281|       VfL Wolfsburg|       FC Schalke 04|Kutschke, Stefan|       vfl-wolfsburg|      22|\n|Mandzukic, Mario|2013-08-17T15:30:00|    false|    false| 21253| Eintracht Frankfurt|      Bayern München|Mandzukic, Mario|     bayern-muenchen|     133|\n|      Kruse, Max|2013-08-17T18:30:00|    false|    false| 21296|Borussia Möncheng...|         Hannover 96|      Kruse, Max|borussia-möncheng...|     152|\n|           Ronny|2013-08-18T15:30:00|    false|     true| 21330|      1. FC Nürnberg|          Hertha BSC|           Ronny|          hertha-bsc|     253|\n|   Robben, Arjen|2013-08-24T15:30:00|    false|    false| 21407|      Bayern München|      1. FC Nürnberg|   Robben, Arjen|     bayern-muenchen|     127|\n|         Raffael|2013-08-31T15:30:00|    false|    false| 21586|Borussia Möncheng...|       Werder Bremen|         Raffael|borussia-möncheng...|     154|\n|      Kruse, Max|2013-08-31T15:30:00|    false|    false| 21588|Borussia Möncheng...|       Werder Bremen|      Kruse, Max|borussia-möncheng...|     152|\n|           Diego|2013-08-31T15:30:00|    false|    false| 21570|       VfL Wolfsburg|          Hertha BSC|           Diego|       vfl-wolfsburg|      13|\n|Mandzukic, Mario|2013-09-14T15:30:00|    false|    false| 21874|      Bayern München|         Hannover 96|Mandzukic, Mario|     bayern-muenchen|     133|\n|         Raffael|2013-09-20T20:30:00|    false|    false| 22091|Borussia Möncheng...|Eintracht Braunsc...|         Raffael|borussia-möncheng...|     154|\n|      Kruse, Max|2013-09-20T20:30:00|    false|     true| 22093|Borussia Möncheng...|Eintracht Braunsc...|      Kruse, Max|borussia-möncheng...|     152|\n|         Raffael|2013-09-20T20:30:00|    false|    false| 22094|Borussia Möncheng...|Eintracht Braunsc...|         Raffael|borussia-möncheng...|     154|\n|Mandzukic, Mario|2013-09-21T18:30:00|    false|    false| 22139|       FC Schalke 04|      Bayern München|Mandzukic, Mario|     bayern-muenchen|     133|\n+----------------+-------------------+---------+---------+------+--------------------+--------------------+----------------+--------------------+--------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mjoindf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [PlayerName: string, MatchDateTime: string ... 8 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082094_627465405",
      "id": "20180702-132557_1889549960",
      "dateCreated": "2021-07-08 15:28:02.094",
      "status": "READY"
    },
    {
      "text": "%md\n\n### Exercise\n\nUse some SQL statement to verify the result quality. How many goals are there in `goals`? How many goals are in the result?\n\nPlease note that Wikipedia reports 967 goals for the season 2013/14.",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.094",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eExercise\u003c/h3\u003e\n\u003cp\u003eUse some SQL statement to verify the result quality. How many goals are there in \u003ccode\u003egoals\u003c/code\u003e? How many goals are in the result?\u003c/p\u003e\n\u003cp\u003ePlease note that Wikipedia reports 967 goals for the season 2013/14.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082094_1870218352",
      "id": "20180702-133706_667719327",
      "dateCreated": "2021-07-08 15:28:02.094",
      "status": "READY"
    },
    {
      "text": "%sql\n\nSELECT ...\nFROM ...\nWHERE ...",
      "user": "admin",
      "dateUpdated": "2021-07-08 15:28:02.095",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "count(DISTINCT GoalID)": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625758082095_1031532775",
      "id": "20180702-133118_483960412",
      "dateCreated": "2021-07-08 15:28:02.095",
      "status": "READY"
    }
  ],
  "name": "02-SemistructuredData",
  "id": "2GCUENUFU",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}